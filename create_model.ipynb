{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:01:50.847927Z",
     "start_time": "2024-10-29T09:01:45.126940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa.display\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "id": "c9272ced716478d7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T09:01:51.875400Z",
     "start_time": "2024-10-29T09:01:51.864216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 指定 STFT 參數\n",
    "load_dotenv()\n",
    "sample_rate = int(os.getenv('sample_rate'))\n",
    "n_mels = int(os.getenv('n_mels'))\n",
    "# n_fft = int(os.getenv('n_fft'))\n",
    "\n",
    "print(f'Sample rate: {sample_rate}, n_mels: {n_mels}')"
   ],
   "id": "383eb8331f64ea50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 48000, n_mels: 128\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:02:31.810127Z",
     "start_time": "2024-10-29T09:01:52.827864Z"
    }
   },
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_segmented_files(directory):\n",
    "    wav_files = []\n",
    "    leak_wav_files = []\n",
    "    for dir in os.listdir(directory):\n",
    "        if not os.path.isdir(os.path.join(directory, dir)):\n",
    "            continue\n",
    "        for file in os.listdir(os.path.join(directory, dir)):\n",
    "            if not file.endswith(\".wav\"):\n",
    "                continue\n",
    "            file_path = os.path.join(directory, dir, file)\n",
    "            y, sr = librosa.load(file_path, sr=None)\n",
    "            filename = f'{dir}_{file}'\n",
    "            if 'no-leak' in dir:\n",
    "                wav_files.append((y, sr, filename))\n",
    "            else:\n",
    "                leak_wav_files.append((y, sr, filename))\n",
    "    return wav_files, leak_wav_files\n",
    "\n",
    "def create_dataset(directory, max_length=None):\n",
    "    wav_files, leak_wav_files = load_segmented_files(directory)\n",
    "    \n",
    "    # 將資料轉為 NumPy 格式\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for audio, sr, filename in wav_files:\n",
    "        X.append((audio, sr))\n",
    "        y.append(0)  # wav_files 標記為 0\n",
    "    \n",
    "    for audio, sr, filename in leak_wav_files:\n",
    "        X.append((audio, sr))\n",
    "        y.append(1)  # leak_wav_files 標記為 1\n",
    "    \n",
    "    return X, np.array(y)\n",
    "\n",
    "# 使用範例\n",
    "directory = 'training_data'\n",
    "X, y = create_dataset(directory)\n",
    "\n",
    "print(f\"總樣本數: {len(X)}\")\n",
    "print(f\"標籤分佈: {np.bincount(y)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總樣本數: 12717\n",
      "標籤分佈: [10641  2076]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-29T09:02:39.626492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_features(audio, sr, n_mels=128, n_fft=2048, hop_length=512, max_len=128):\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "    log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    # 轉置以符合 (時間, 頻率) 的形狀\n",
    "    log_mel_spectrogram = log_mel_spectrogram.T  # 形狀變為 (時間, n_mels)\n",
    "    \n",
    "    # 填充或截斷至 max_len\n",
    "    if log_mel_spectrogram.shape[0] < max_len:\n",
    "        pad_width = max_len - log_mel_spectrogram.shape[0]\n",
    "        log_mel_spectrogram = np.pad(log_mel_spectrogram, ((0, pad_width), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        log_mel_spectrogram = log_mel_spectrogram[:max_len, :]\n",
    "    \n",
    "    return log_mel_spectrogram\n",
    "\n",
    "def preprocess_data(X, max_len=128):\n",
    "    features = []\n",
    "    for audio, sr in X:\n",
    "        feature = extract_features(audio, sr, max_len=max_len)\n",
    "        features.append(feature)\n",
    "    return np.array(features)\n",
    "\n",
    "# 預處理資料\n",
    "max_len = 128  # 您可以根據需求調整\n",
    "X_features = preprocess_data(X, max_len=max_len)\n",
    "\n",
    "print(f\"特徵形狀: {X_features.shape}\")  # 預期形狀: (樣本數, max_len, n_mels)\n"
   ],
   "id": "5cb187713d43dd39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 正規化特徵\n",
    "X_features = (X_features - np.mean(X_features)) / np.std(X_features)\n",
    "\n",
    "# 擴展維度以符合 CNN 輸入 (樣本數, 高, 寬, 通道)\n",
    "X_features = np.expand_dims(X_features, -1)  # 新形狀: (樣本數, max_len, n_mels, 1)\n",
    "\n",
    "# 分割訓練集與測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"訓練集形狀: {X_train.shape}\")\n",
    "print(f\"測試集形狀: {X_test.shape}\")\n"
   ],
   "id": "14970057696e42b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T08:55:32.206928Z",
     "start_time": "2024-10-29T08:55:23.392192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def create_cnn_model(input_shape=(128, 128, 1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))  # 二元分類使用 sigmoid 激活函數\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 建立模型\n",
    "input_shape = (128, 128, 1)  # 調整後的頻譜圖形狀\n",
    "model = create_cnn_model(input_shape)\n",
    "model.summary()\n"
   ],
   "id": "e5d13120a6048b8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 126, 126, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 63, 63, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1605696   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,698,433\n",
      "Trainable params: 1,698,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T08:55:35.871218Z",
     "start_time": "2024-10-29T08:55:34.671371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 假設 X_train 和 X_test 經過特徵提取並已調整維度\n",
    "X_train_expanded = np.expand_dims(X_train, -1)\n",
    "X_test_expanded = np.expand_dims(X_test, -1)\n",
    "\n",
    "# 訓練模型\n",
    "history = model.fit(X_train_expanded, y_train, epochs=30, batch_size=32, validation_data=(X_test_expanded, y_test))\n"
   ],
   "id": "eb722b82e90ac3d",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m X_test_expanded \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(X_test, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# 訓練模型\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_expanded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_test_expanded\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\leak_detection\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\leak_detection\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m    100\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtypes\u001B[38;5;241m.\u001B[39mas_dtype(dtype)\u001B[38;5;241m.\u001B[39mas_datatype_enum\n\u001B[0;32m    101\u001B[0m ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEagerTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 評估模型\n",
    "test_loss, test_accuracy = model.evaluate(X_test_expanded, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")\n"
   ],
   "id": "bc424034a5d352d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "70c5f696df14eef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
